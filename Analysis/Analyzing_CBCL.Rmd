---
title: "Analyzing the CBCL"
author: "Leandro Ledesma"
date: "2025-06-30"
output: html_document
---


### Universal block code settings

```{r setup}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(comment = NULL)
knitr::opts_chunk$set(warning = FALSE)

```

```{r loading in the packages, warning = FALSE}
library(tidyverse)
library(ggplot2)
library(psych)
library(readxl)
library(kableExtra)
library(lavaan)
library(parallel) # detectCores()
library(effects) # allEffects()
library(ggpubr) # stat_pvalue_manual()

```



# Read in the data
```{r reading in the meta data}
# Set working directory
setwd("~/KBB/Data/FINAL_DS/Behavioral/Adults")

# Read in the data
C3_6 <- read_excel("CBC_3_6.xlsx")
C6_18 <- read_excel("CBC_6_18.xlsx")

# Convert all vars to numeric (for C3_6, item 100 will turn into NAs, for C6_18 itsm 163 and 120 will turn into NAs)
C3_6 <- data.frame(sapply(C3_6, function(x) as.numeric(x)))
C6_18 <- data.frame(sapply(C6_18, function(x) as.numeric(x)))

# Identify and drop any duplicate IDs
C3_6_dup <- C3_6$Child_ID[duplicated(C3_6$Child_ID)]
C6_18_dup <- C6_18$Child_ID[duplicated(C6_18$Child_ID)]

# Remove duplicates
C3_6_2 <- C3_6 %>% filter(!Child_ID %in% C3_6_dup)
C6_18_2 <- C6_18 %>% filter(!Child_ID %in% C6_18_dup)
cat(length(C3_6_dup),"children have been removed for being duplicates in the CBCL3-6 \n")
cat(length(C6_18_dup),"children have been removed for being duplicates in the CBCL6-18 \n")

```

# Read in demographic information
```{r read in demographic info}
# Set the working directory to where the demographic information is
setwd("C:/Users/lledesma.TIMES/Documents/KBB/Data/FINAL_DS/Demographics")

# Load in the data
demo <- read_excel("Demographics.xlsx")

# Identify and drop duplicate IDs from demo
duplicated_demo_IDs <- demo$Child_ID[duplicated(demo$Child_ID)]
demo <- demo %>% filter(!Child_ID %in% duplicated_demo_IDs)
cat(length(duplicated_demo_IDs),"children have been removed for being duplicates in the demographics \n")

# Add demographics into each dataframe
C3_6_3 <- C3_6_2 %>%
  left_join(demo, by = "Child_ID")
C6_18_3 <- C6_18_2 %>%
  left_join(demo, by = "Child_ID")

# Remove children outside the correct age range
c3_6_bad_age <- na.omit(C3_6_3$Child_ID[C3_6_3$Age >= 7 | C3_6_3$Age <= 2])
C6_18_bad_age <- na.omit(C6_18_3$Child_ID[C6_18_3$Age >= 19 | C6_18_3$Age <= 5])
cat(length(c3_6_bad_age),"children have been removed from CBCL3-6 for being 7 or older or 2 or younger\n")
cat(length(C6_18_bad_age),"children have been removed from CBCL6-18 for being 19 or older or 5 or younger\n")

C3_6_4 <- C3_6_3 %>%
  filter(!Child_ID %in% c3_6_bad_age)
C6_18_4 <- C6_18_3 %>%
  filter(!Child_ID %in% C6_18_bad_age)

# Drop unnecessary variables not needed for analysis
C3_6_5 <- select(C3_6_4, CBC3_6_1:CBC3_6_100)
C6_18_5 <- select(C6_18_4, CBC6_18_1:CBC6_18_120)

# Rename the items to make them shorter
names(C3_6_5) <- paste0("I",1:length(C3_6_5))
names(C6_18_5) <- paste0("I",1:length(C6_18_5))
```
# Organizing items within the assessments by scales (CBCL3-6)

```{r organizing items by scales CBCL3 to 6}
#### Internalizing Problems
emo_reac <- c(21, 46, 51, 79, 82, 83, 92, 97, 99)
anx_depr <- c(10, 33, 37, 43, 47, 68, 87, 90)
som_comp <- c(1, 7, 12, 19, 24, 39, 45, 52, 78, 86, 93)
withdr <- c(2, 4, 23, 62, 67, 70, 71, 98)

# Sleep its own thing
sleep_prob <- c(22, 38, 48, 64, 74, 84, 94)

# Externalizing Problems
atten_prob <- c(5, 6, 56, 59, 95)
aggr_beh <- c(8, 15, 16, 18, 20, 27, 29, 35, 40, 42, 44, 53, 58, 66, 69, 81, 85, 88, 96)

# This is its own thing
othr_prob <- c(3, 9, 11, 13, 14, 17, 25, 26, 28, 30, 31, 32, 34, 36, 41, 49,
               50, 54, 55, 57, 60, 61, 63, 65, 72, 73, 75, 76, 77, 80, 89, 91, 100)

# DSM orientated scaled
depress_scale <- c(13, 24, 38, 43, 49, 50, 71, 74, 89, 90)
anxiet_scale <- c(10, 22, 28, 32, 37, 47, 48, 51, 87, 99)
autism_scale <- c(4, 7, 21, 23, 25, 63, 67, 70, 76, 80, 92, 98)
ADHD_scale <- c(5, 6, 8, 16, 36, 59)
opp_def_prob_scale <- c(15, 20, 44, 81, 85, 88)

```



```{r cbcl3 to 6 descriptives of scales}
# Obtain an average for scales of internalizing problems
ER <- rowSums(C3_6_5[,emo_reac], na.rm = T)
AD <-  rowSums(C3_6_5[,anx_depr], na.rm = T)
SC <-  rowSums(C3_6_5[,som_comp], na.rm = T)
W <- rowSums(C3_6_5[,withdr], na.rm = T)

# Obtain the scales for externalizing problems
AP <- rowSums(C3_6_5[,atten_prob], na.rm = T)
AB <- rowSums(C3_6_5[,aggr_beh], na.rm = T)

# Obtain the scale for sleep problem
SP <- rowSums(C3_6_5[,sleep_prob], na.rm = T)

# Obtain the sum scores for other
O <- rowSums(C3_6_5[,othr_prob], na.rm = T)

# Create a dataset with these new scales
c3_6_scales <- data.frame(ER, AD, SC, W, SP, AP, AB, O)

# Let's view the distribution of problems by scale type
c3_6_scales %>%
  pivot_longer(cols = ER:O, names_to = "Scales", values_to = "Problems") %>%
  mutate(Construct = case_when(
    Scales %in% c("ER", "AD", "SC", "W") ~ "Internalizing",
    Scales %in% c("AP", "AB") ~ "Externalizing",
    Scales %in% c("O","SP") ~ "None"
  )) %>% 
  ggplot(aes(x = Scales, y = Problems, fill = Construct)) +
  geom_violin() + 
  geom_jitter(width = .1, size = .25) +
  theme_classic()

# Let's view correlations
c3_6_scales$int_prob <- rowSums(c3_6_scales[, c("ER","AD","SC","W")])
c3_6_scales$ext_prob <- rowSums(c3_6_scales[, c("AP","AB")])
c3_6_scales$gen_prob <- rowSums(c3_6_scales)
round(cor(c3_6_scales),2)

```


# Running Traditional CFA on the CBCL3-6 (Specify the models)

Okay so we can run a traditional CFA which would save us a lot of time and probably simplyfy things- let's do that. 
We will compare three models
- General factor
- Two factor (with one item correlating?)
- Hierarchical model

We created CFA that make sense with how the assessment is scored

```{r running categorical CFA on the cbcl 3 to 6}
# Shortcut
# paste(names(c3_6_scales), collapse = " + ")

# Specify the model for a general factor model
gen_mod <-'

  # Measurement model (fixed = 1; free = 7)
  TPS =~ 1*ER + AD + SC + W + SP + AP + AB + O
  
  # Latent variable variance (free = 1)
  TPS ~~ TPS
  
  # Residual variances (free = 8)
  ER ~~ ER
  AD ~~ AD
  SC ~~ SC
  W ~~ W
  AP ~~ AP
  AB ~~ AB
  SP ~~ SP
  O ~~ O

  # Total estimated parameters = 8*9/2 = 36
  # Freely estimated parameters = 7 + 1 + 8 = 16
  # df = 36 - 16 = 20
'

# Specify the model for first order factors (do not load SP to any factor)
first_mod <-'

  # Measurement model (fixed = 3; free = 5)
  IPS =~ 1*ER + AD + SC + W
  EPS =~ 1*AP + AB
  OTH =~ 1*SP + O
  
  # Latent variable variance (free = 3)
  IPS ~~ IPS
  EPS ~~ EPS
  OTH ~~ OTH
  
  # Latent variable covariance (free = 3)
  IPS ~~ EPS
  IPS ~~ OTH
  OTH ~~ EPS
  
  # Residual variances (free = 8)
  ER ~~ ER
  AD ~~ AD
  SC ~~ SC
  W ~~ W
  AP ~~ AP
  AB ~~ AB
  SP ~~ SP
  O ~~ O

  # Total estimated parameters = 8*9/2 = 36
  # Freely estimated parameters = 5 + 3 + 3 + 8  = 19
  # df = 36 - 19 = 17
'

# Specify the second order factor
second_mod <-'

  # Measurement model (fixed = 2; free = 4)
  IPS =~ 1*ER + AD + SC + W
  EPS =~ 1*AP + AB
  
  # Second order factor (free = 4)
  TPS =~ NA*IPS + EPS + SP + O
  
  # Latent variable variance (fixed = 1, free = 2)
  IPS ~~ IPS
  EPS ~~ EPS
  TPS ~~ 1*TPS
  
  # Latent variable covariance (fixed = 1)
  IPS ~~ 0*EPS
  
  # Residual variances (free = 8)
  ER ~~ ER
  AD ~~ AD
  SC ~~ SC
  W ~~ W
  AP ~~ AP
  AB ~~ AB
  SP ~~ SP
  O ~~ O

  # Total estimated parameters = 8*9/2 = 36
  # Freely estimated parameters = 4 + 4 + 2 + 8 = 18
  # df = 36 - 18 = 18
'

# Specify the second order factor but allow correlations between the first order factors
second_cor_mod <-'

  # Measurement model (fixed = 2; free = 4)
  IPS =~ 1*ER + AD + SC + W
  EPS =~ 1*AP + AB
  
  # Second order factor (free = 4)
  TPS =~ NA*IPS + EPS + SP + O
  
  # Latent variable variance (fixed = 1, free = 2)
  IPS ~~ IPS
  EPS ~~ EPS
  TPS ~~ 1*TPS
  
  # Latent variable covariance (free = 1)
  IPS ~~ EPS
  
  # Residual variances (free = 8)
  ER ~~ ER
  AD ~~ AD
  SC ~~ SC
  W ~~ W
  AP ~~ AP
  AB ~~ AB
  SP ~~ SP
  O ~~ O

  # Total estimated parameters = 8*9/2 = 36
  # Freely estimated parameters = 4 + 4 + 2 + 1 + 8 = 19
  # df = 36 - 19 = 17
'

# Create a CFA model
fit1 <- cfa(gen_mod, data = select(c3_6_scales, ER:O))
fit2 <- cfa(first_mod, data = select(c3_6_scales, ER:O))
fit3 <- cfa(second_mod, data = select(c3_6_scales, ER:O))
fit4 <- cfa(second_cor_mod, data = select(c3_6_scales, ER:O))

```

# Load custom functions for model comparison
```{r model comparison custom functions}
get_cfa_metrics2 <- function(models) {
  lambda_list <- list()
  theta_list <- list()
  r2_df_list <- list()
  fit_metrics_list <- list()
  
  for (name in names(models)) {
    fit <- models[[name]]
    
    # extract r^2
    r2 <- inspect(fit, "r2")
    
    # extract the names of indicators
    indicator.names <- row.names(inspect(fit, "std")$lambda)
    
    # keep only the r^2 of indicators
    r2.indicators <- r2[names(r2) %in% indicator.names] 
    
    # Fit metrics
    metrics <- c(
      fitMeasures(fit, c("chisq", "df", "cfi", "tli", "rmsea", "srmr", "aic", "bic", "bic2")),
      mean(r2.indicators)
    )
    names(metrics)[length(metrics)] <- "r^2"
    fit_metrics_list[[name]] <- metrics
    
    # Lambda
    lambda <- inspect(fit, "std")$lambda
    colnames(lambda) <- paste0(name, "_", colnames(lambda))  
    lambda_list[[name]] <- lambda
    
    # Theta (diagonal only)
    theta_diag <- diag(inspect(fit, "std")$theta)
    theta_list[[name]] <- theta_diag
    
    # R² table
    r2_vals <- inspect(fit, "r2")
    r2_df <- data.frame(var = names(r2_vals), r2 = r2_vals)
    names(r2_df)[2] <- paste0(name, "_r2") 
    r2_df_list[[name]] <- r2_df
  }
  
  # Find variable order from the model with the most R² entries
  longest_vec <- r2_df_list[[which.max(sapply(r2_df_list, nrow))]]$var
  
  # Merge and align R² across models
  r2_combined <- Reduce(function(x, y) merge(x, y, by = "var", all = TRUE), r2_df_list)
  r2_combined <- r2_combined[match(longest_vec, r2_combined$var), ]
  rownames(r2_combined) <- r2_combined$var
  r2_combined$var <- NULL
  
  # Combine other metrics
  lambda_combined <- do.call(cbind, lambda_list)
  theta_combined <- do.call(cbind, theta_list)
  fit_metrics_combined <- do.call(cbind, fit_metrics_list)
  
  # Return all results
  return(list(
    fit_metrics = fit_metrics_combined,
    lambda = lambda_combined,
    theta = theta_combined,
    r2 = r2_combined
  ))
}
```

# CBCL 3-6 Model comparisons

Model 2 and Model 4 produced Heywood Cases- thus they are eliminated by default. From the remaining models, Model 3 outperformed Model 1, confirming that the assessment is capturing the factor structure as intended. 

```{r CBCL 3 to 6 model comparisons}
# Place all cfa metrics within a list
fit_list <- list(
  mod1 = fit1, 
  mod2 = fit2, 
  mod3 = fit3,
  mod4 = fit4
)

# Extract metrics from each model
cfa_metrics <- get_cfa_metrics2(fit_list)
cfa_metrics_df <- round(cfa_metrics$fit_metrics, 3) %>%
  t()
  
# Change the row names
rownames(cfa_metrics_df) <- c("General Factor", "Two Factor", "Hierarchical Two Factor", "Hierarchical Two Factors Correlated")
cfa_metrics_df %>%
  kbl(caption = "Fit of the Four Factor Models on the CBCL3-6") %>%
  kable_classic(full_width = F) %>%
  footnote(general = "All χ² goodness-of-fit tests were statistically significant at p <.001. CFI = comparitive fit index; TLI = tucker-lewis index; RMSEA = root mean square error of approximation; SRMR = standardized root mean squared residual")
```
# Visualize the CBCL 3-6 
```{r visualize the CBCL 3 to 6}
library(semPlot)
library(semptools)
# Plot the diagram (Make it larger on purpose)
p <- semPaths(fit3, 
         whatLabels = "std",        # Show standardized estimates
         edge.label.cex = 1.6,       # Size of edge labels (loadings/errors)
         sizeMan = 5,               # Makes indicator boxes LARGER (default=5)
         sizeMan2 = 7,              # Controls height (smaller = taller boxes)
         node.width = 1.8,          # Adjusts node width (wider boxes)
         border.width = 1.4,        # Thickness of box borders
         sizeLat = 5,
         label.cex = 1.3,             # Size of text inside boxes
         edge.color = "black",      # All lines black
         edge.width = 1.4,          # Thickness of arrows
         curve = .5,              # Curvature of double-headed arrows
         rotation = 4,             # Rotate layout
         mar = c(5, 12, 5, 8),     # Margins (D, L, U, R)
         shapeMan = "rectangle",   # Ensures boxes are rectangular
         aspect = 2                # Adjust aspect ratio (higher = wider)
)

# Move the error variance to the back
my_rotate_resid_list <- c(TPS =  90)
p_er <- rotate_resid(p, my_rotate_resid_list)
plot(p_er)
```




# Organizing items within the assessments by scales (CBCL6-18)

```{r organizing items within sacles in the CBCL 6 to 18}
### Internalizing Problems
anx_dep <- c(14, 29, 30, 31, 32, 33, 35, 45, 50, 52, 71, 91, 112)
wit_dep <- c(5, 42, 65, 69, 75, 102, 103, 111)
som_com <- c(47, 49, 51, 54, 56) #Q56 not program correctly- this measure is inaccurate

#### Not in a scale bu separate from other problems
soc_pro <- c(11, 12, 25, 27, 34, 36, 38, 48, 62, 64, 79)
tho_pro <- c(9, 18, 40, 46, 58, 59, 60, 66, 70, 76, 83, 84, 85, 92, 100)
att_pro <- c(1, 4, 8, 10, 13, 17, 41, 61, 78, 80)

#### Externalizing Problems
rul_beh <- c(2, 26, 28, 39, 43, 63, 67, 72, 73, 81, 82, 90, 96, 99, 101, 105, 106)
agg_beh <- c(3, 16, 19, 20, 21, 22, 23, 37, 57, 68, 86, 87, 88, 89, 94, 95, 97, 104)

# Other Problems
oth_pro <- c(6, 7, 15, 24, 44, 53, 55, 74, 77, 93, 98, 107, 108, 109, 110, 113)
```



```{r cbcl6 to 18 descriptives of scales}
# Obtain an average for scales of internalizing problems
AD <-  rowSums(C6_18_5[,anx_dep], na.rm = T)
WD <-  rowSums(C6_18_5[,wit_dep], na.rm = T)
SC <-  rowSums(C6_18_5[,som_com], na.rm = T)

# Obtain the scales for externalizing problems
RB <- rowSums(C6_18_5[,rul_beh], na.rm = T)
AB <- rowSums(C6_18_5[,agg_beh], na.rm = T)

# Obtain the scale for sleep, thoughts and attention problems
SP <- rowSums(C6_18_5[,soc_pro], na.rm = T)
TP <- rowSums(C6_18_5[,tho_pro], na.rm = T)
AP <- rowSums(C6_18_5[,att_pro], na.rm = T)

# Obtain the sum scores for other
O <- rowSums(C6_18_5[,oth_pro], na.rm = T)

# Create a dataset with these new scales
c6_18_scales <- data.frame(AD, WD, SC, RB, AB, SP, TP, AP, O)

# Let's view the distribution of problems by scale type
c6_18_scales %>%
  pivot_longer(cols = AD:O, names_to = "Scales", values_to = "Problems") %>%
  mutate(Construct = case_when(
    Scales %in% c("AD", "WD", "SC") ~ "Internalizing",
    Scales %in% c("RB", "AB") ~ "Externalizing",
    Scales %in% c("SP", "TP", "AP", "O") ~ "None"
  )) %>% 
  ggplot(aes(x = Scales, y = Problems, fill = Construct)) +
  geom_violin(width = 1) + 
  geom_jitter(width = .05, size = .25) +
  theme_classic()

# Let's view correlations
c6_18_scales$int_prob <- rowSums(c6_18_scales[, c("AD", "WD", "SC")])
c6_18_scales$ext_prob <- rowSums(c6_18_scales[, c("RB","AB")])
c6_18_scales$gen_prob <- rowSums(c6_18_scales)
round(cor(c6_18_scales),2)

```


# Running Traditional CFA on the CBCL6-18 (Specify the models)

Okay so we can run a traditional CFA which would save us a lot of time and probably simplyfy things- let's do that. 
We will compare three models
- General factor
- Two factor (with one item correlating?)
- Hierarchical model

We created CFA that make sense with how the assessment is scored

```{r running categorical CFA on the cbcl 6 to 18}
# Shortcut
# paste(names(c6_18_scales), collapse = " + ")

# Specify the model for a general factor model
gen_mod <-'

  # Measurement model (fixed = 1; free = 8)
  TPS =~ 1*AD + WD + SC + RB + AB + SP + TP + AP + O 
  
  # Latent variable variance (free = 1)
  TPS ~~ TPS
  
  # Residual variances (free = 9)
  AD ~~ AD
  WD ~~ WD
  SC ~~ SC
  RB ~~ RB
  AB ~~ AB
  SP ~~ SP
  TP ~~ TP
  AP ~~ AP
  O ~~ O 

  # Total estimated parameters = 9*10/2 = 45
  # Freely estimated parameters = 8 + 1 + 9 = 18
  # df = 45 - 18 = 27
'

# Specify the model for first order factors
first_mod <-'

  # Measurement model (fixed = 3; free = 6)
  IPS =~ 1*AD + WD + SC
  EPS =~ 1*RB + AB
  OTH =~ 1*SP + TP + AP + O
  
  # Latent variable variance (free = 3)
  IPS ~~ IPS
  EPS ~~ EPS
  OTH ~~ OTH
  
  # Latent variable covariance (free = 3)
  IPS ~~ EPS
  IPS ~~ OTH
  EPS ~~ OTH
  
  # Residual variances (free = 9)
  AD ~~ AD
  WD ~~ WD
  SC ~~ SC
  RB ~~ RB
  AB ~~ AB
  SP ~~ SP
  TP ~~ TP
  AP ~~ AP
  O ~~ O 

  # Total estimated parameters = 9*10/2 = 45
  # Freely estimated parameters = 6 + 3 + 3 + 9 = 21
  # df = 45 - 21 = 24
'

# Specify the second order factor
second_mod <-'

  # Measurement model (fixed = 2; free = 3)
  IPS =~ 1*AD + WD + SC
  EPS =~ 1*RB + AB
  
  # Second order factor (free = 6)
  TPS =~ NA*IPS + EPS + SP + TP + AP + O
  
  # Latent variable variance (fixed = 1, free = 2)
  IPS ~~ IPS
  EPS ~~ EPS
  TPS ~~ 1*TPS
  
  # Latent variable covariance (fixed = 1)
  IPS ~~ 0*EPS
  
  # Residual variances (free = 9)
  AD ~~ AD
  WD ~~ WD
  SC ~~ SC
  RB ~~ RB
  AB ~~ AB
  SP ~~ SP
  TP ~~ TP
  AP ~~ AP
  O ~~ O 

  # Total estimated parameters = 9*10/2 = 45
  # Freely estimated parameters = 3 + 6 + 2 + 9 = 20
  # df = 45 - 20 = 25
'

# Specify the second order factor but allow correlations between the first order factors
second_cor_mod <-'

  # Measurement model (fixed = 2; free = 3)
  IPS =~ 1*AD + WD + SC
  EPS =~ 1*RB + AB
  
  # Second order factor (free = 6)
  TPS =~ NA*IPS + EPS + SP + TP + AP + O
  
  # Latent variable variance (fixed = 1, free = 2)
  IPS ~~ IPS
  EPS ~~ EPS
  TPS ~~ 1*TPS
  
  # Latent variable covariance (free = 1)
  IPS ~~ EPS
  
  # Residual variances (free = 9)
  AD ~~ AD
  WD ~~ WD
  SC ~~ SC
  RB ~~ RB
  AB ~~ AB
  SP ~~ SP
  TP ~~ TP
  AP ~~ AP
  O ~~ O 


  # Total estimated parameters = 9*10/2 = 45
  # Freely estimated parameters = 3 + 6 + 2 + 1 + 9 = 21
  # df = 45 - 21 = 24
'

# Create a CFA model
fit1 <- cfa(gen_mod, data = select(c6_18_scales, AD:O))
fit2 <- cfa(first_mod, data = select(c6_18_scales, AD:O))
fit3 <- cfa(second_mod, data = select(c6_18_scales, AD:O))
fit4 <- cfa(second_cor_mod, data = select(c6_18_scales, AD:O))

```


# CBCL 6-18 Model comparisons

Model 3 checks out AND also has an extra degree of freedom

```{r CBCL 6 to 18 model comparisons}
# Place all cfa metrics within a list
fit_list <- list(
  mod1 = fit1, 
  mod2 = fit2, 
  mod3 = fit3,
  mod4 = fit4
)

# Extract metrics from each model
cfa_metrics <- get_cfa_metrics2(fit_list)
cfa_metrics_df <- round(cfa_metrics$fit_metrics, 3) %>%
  t()
  
# Change the row names
rownames(cfa_metrics_df) <- c("General Factor", "Two Factor", "Hierarchical Two Factor", "Hierarchical Two Factors Correlated")
cfa_metrics_df %>%
  kbl(caption = "Fit of the Four Factor Models on the CBCL6-18") %>%
  kable_classic(full_width = F) %>%
  footnote(general = "All χ² goodness-of-fit tests were statistically significant at p <.001. CFI = comparitive fit index; TLI = tucker-lewis index; RMSEA = root mean square error of approximation; SRMR = standardized root mean squared residual")
```
# Visualize the CBCL 6-18 
```{r visualize the CBCL 6 to 18}
library(semPlot)
semPaths(fit1, 
        whatLabels = "std",
        sizeMan = 5,
        node.width = 1,
        edge.label.cex = .75,
        rotation = 4,
        style = "ram",
        mar = c(2,6,2,6))  # D L U R


library(semPlot)
library(semptools)

# Plot the diagram (Make it larger on purpose)
p2 <- semPaths(fit1, 
         whatLabels = "std",        # Show standardized estimates
         edge.label.cex = 1.8,       # Size of edge labels (loadings/errors)
         sizeMan = 5,               # Makes indicator boxes LARGER (default=5)
         sizeMan2 = 5,              # Controls height (smaller = taller boxes)
         node.width = 1.8,          # Adjusts node width (wider boxes)
         border.width = 1.4,        # Thickness of box borders
         sizeLat = 5,
         label.cex = 1.3,             # Size of text inside boxes
         edge.color = "black",      # All lines black
         edge.width = 1.4,          # Thickness of arrows
         curve = 2.3,              # Curvature of double-headed arrows
         rotation = 4,             # Rotate layout
         mar = c(5, 12, 5, 8),     # Margins (D, L, U, R)
         shapeMan = "rectangle",   # Ensures boxes are rectangular
         aspect = 2                # Adjust aspect ratio (higher = wider)
)

plot(p2)
```