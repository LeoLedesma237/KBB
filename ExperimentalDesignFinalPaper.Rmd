---
title: "Experimental Design Final Paper"
author: "Leandro Ledesma"
date: "2024-12-06"
output: html_document
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(comment = "")
knitr::opts_chunk$set(warning = FALSE)

```

```{r load in packages, echo = FALSE}
library(tidyverse)
library(ggplot2)
library(psych)
library(readxl)
library(kableExtra)
library(lme4)
library(lmerTest)
library(performance) # ICC
library(car)
library(emmeans)
library(lmerTest)
library(simr) # Power Simulation
library(future) # plan(); for parallel processing
library(effectsize)
```


     
```{r loading in all required data, echo = F, include = F}
# Set working directory to where your GitHub repository is
GitHub = "C:/Users/lledesma.TIMES/Documents/GitHub/ONR_MBAP/"

# Set working directory to where the final data is
setwd(paste0(GitHub,"TimesServer/FINAL_DS/"))

# Load in VR behavioral data
All_VR <- read.csv("VR/NbackAccuracyWide.csv")

# Load in the VR RT 
All_RT <- read.csv("VR/NbackReactionTimeWide.csv")

# Load in demographics
demo <- read_excel("Demographics/ComprehensiveDescriptives.xlsx")

# Clean demo to include subjects we care for
demo <- demo %>%
  filter(Pilot == "Yes" & 
         Sex != "Intersex/Other")

# Introduce demographics into the GnG VR
All_VR <- All_VR %>%
  right_join(demo, by = "ID") %>%
  filter(!(Day %in% c("Day0", "DatenotsavedintheVisitorLog")))

# Introduce demographics into the GnG RT 
All_RT <- All_RT %>%
  right_join(demo, by = "ID") %>%
  filter(!(Day %in% c("Day0", "DatenotsavedintheVisitorLog")))


# Combine to only keep the Arrows and Reverse Arrows with No Distractor Condition (Wide format)
VR <- All_VR %>%
  filter(BlockName %in% c("2-Back AR w ND", "2-Back RAR w ND")) %>%
  group_by(ID, Day) %>%
  summarise(Sex,
            Age,
            trial.num_Non.Target = sum(trial.num_Non.Target),
            trial.num_Target = sum(trial.num_Target),
            trial.mean.correct_Non.Target = mean(trial.mean.correct_Non.Target),
            trial.mean.correct_Target = mean(trial.mean.correct_Target)) %>%
  unique() %>%
  ungroup() %>%
  mutate(ID_Day = paste0(ID,"_",Day))

# Combine to only keep the Color and Shape Fixed IS and Color and Shape Conditions for RT (wide format)
RT <- All_RT %>%
  filter(BlockName %in% c("2-Back AR w ND", "2-Back RAR w ND")) %>%
  group_by(ID, Day) %>%
  summarise(Sex,
            Age,
            Correct_Target_ms  = mean(Correct_Target_ms)) %>%
  unique() %>%
  ungroup() %>%
  mutate(ID_Day = paste0(ID,"_",Day))


# Load in EEG data
load("EEG ERPs/AR_RAR_FinalERPData.RData")
```

```{r outlier removal, out.width = "50%", include= F,}
# Created a vector of outlier IDs
outlierIDs <- c(4, 266, 332, 222)

# Print out how many outlier IDs were removed
paste0("The number of outlier IDs that had all their testing sessions removed from further analysis is: ", length(outlierIDs))

# Remove outliers
VR <- VR %>%
  filter(!ID %in% outlierIDs)

# Let's transform the data to long
VR.long <- VR %>%
  select(ID, Day, Sex, trial.mean.correct_Target, trial.mean.correct_Non.Target ) %>%
  pivot_longer(cols = c(trial.mean.correct_Non.Target , trial.mean.correct_Target),
               names_to = "Trial.Type",
               values_to = "Performance") %>%
  mutate(Trial.Type = ifelse(Trial.Type == "trial.mean.correct_Target", "Target", "NoTarget"),
         Trial.Type = factor(Trial.Type))

# Sperate the data by trial type
VRTarget <- filter(VR.long, Trial.Type == "Target")

# Let's transform the data to long
VR.long <- VR %>%
  select(ID, Day, Sex, trial.mean.correct_Target, trial.mean.correct_Non.Target ) %>%
  pivot_longer(cols = c(trial.mean.correct_Non.Target , trial.mean.correct_Target),
               names_to = "Trial.Type",
               values_to = "Performance") %>%
  mutate(Trial.Type = ifelse(Trial.Type == "trial.mean.correct_Target", "Target", "NoTarget"),
         Trial.Type = factor(Trial.Type))

# Sperate the data by trial type
VRTarget <- filter(VR.long, Trial.Type == "Target")

# Create the unconditional model
AnDVR_unmodel <- lmer(Performance ~ (1|ID), data = VRTarget)
# summary(csVR_unmodel) 

# Paste the ICC
paste0("The adjusted ICC is: ", round(as.data.frame(performance::icc(AnDVR_unmodel)),3)[1])

# Convert variables into factors
VRTarget$Day <- as.factor(VRTarget$Day)
VRTarget$Sex <- as.factor(VRTarget$Sex)

# Check to make sure the dummy coding for day is correct
contrasts(VRTarget$Day)
contrasts(VRTarget$Sex)

# Create the model with the main predictor
Model1 <- lmer(Performance ~  Day + (1|ID), data = VRTarget)

# Create the model with Sex and the main predictor
Model2 <- lmer(Performance ~ Sex  + Day + (1|ID), data = VRTarget)

# Create the model with an interaction between Day and Sex
Model3 <- lmer(Performance ~ Sex  * Day + (1|ID), data = VRTarget)

# Model comparison
anova(Model1, Model2, Model3)

# Report the best model
Anova(Model3, type = "III")

```




###	(5 pts) Problem Statement

Armed services personnel experience stressors during their training and service, including intense physical exertion and sleep deprivation. These stressors present challenges both within and outside the realm of cognition. Though it is generally accepted that mild stress may not negatively affect, or can even improve cognition, chronic or high levels of acute stress diminish cognitive performance. Thus, understanding the impact of common stressors experienced in the armed services and elucidating biomarkers of cognitive performance following such stressors, may inform training and vocational placement of new personnel.  


###	(5 pts) Research Questions

Two main research questions were of interest. The first explored whether different stress conditions (e.g., physical exercise and sleep deprivation) affects working memory performance. The second investigated whether these stress conditions lead to distinct patterns of brain activity during the working memory task.

### (5 pts) Participants

The current sample included 26 individuals with ROTC and/or military experience. Two participants withdrew after only a practice session, leaving 24 participants (age: M = 22.93; SD = 5.06; 10 females). Of these, 14 had ROTC experience, four had military experience (current or veteran) and six had both. They had no known health problems, normal or corrected-to-normal visual acuity, color vision, and hearing, and self-reported English fluency.

### (5 pts) Materials & Procedures

Subjects participated in a 2-Back task while under different conditions of stress. There were three testing sessions in this order. The first day was baseline where the task was completed without any stressor. The second day required participants to use an elliptical machine for 30-60 minutes before engaging in the task. The third and final visit required participants to be sleep deprived while completing the task. 

The 2-Back is a measurement of working memory. This task requires participants to hit a stimulus if it was presented two shapes ago. Thus, participants must consistently update their memory and identify when a stimulus matches one that was presented two shapes back (target) while not reacting to stimuli that do not meet this criterion (non-target). This task also consisted of 300 trials with 20% being target trials and 80% being non-target. 

While subjects were performing the 2-Back, an EEG test was conducted that measured their brain activity. The EEG was prepared before the tasks began and recorded brain electrical activity throughout the duration of both tasks, separately. 

### (5 pts) Measured Variables

Demographics:

- Age: A subject’s age in years
- Sex: Male or Female

Stressors (Factor):

- Day 1 (baseline) 
- Day 2 (exercise)
- Day 3 (sleep deprivation)

2-Back:

- Trial type: Whether the trial was Target or Non-Target
- Outcome: Proportion of correct trials

EEG Nback:

- Trial type: Whether the trial was Target or Non-Target
- Outcome: P300 amplitudes


### (5 pts) Experimental/Study Design

This research design can elucidate how inhibition and working memory are affected by different conditions of stress through a repeated measures design, with each time point representing a level of the factor stress (baseline, exercise, sleep deprivation). The first visit functions as a baseline, that will produce the mean outcome of the sample for working memory ability. Data is then collected on these measures again for two additional days, one where subjects engage in 30-60 minutes of intense exercise and another while subjects are sleep deprived. Obtaining the mean score of this task for these different stress conditions (testing days), we can compare exercise to baseline and sleep deprivation to baseline and see if they are statistically different and to what degree (effect sizes). 

Issues that may arise are highly relate to practice effects. It is known that the consistent exposure to a task can increase the participant’s performance. Ideally, studies will randomize when a subject experiences a specific condition/level of the factor. However, our study decided that baseline will always come first, so the practice effects could dimmish the negative effects on performance from stress if there are any. 

In the context of the three principles of experimental design (control, replication, ethics), this study adequately addresses each one.  For control, we are implementing a well known task that is commonly used to measure working memory and that is compatible with EEG. It was designed to have several trials within the task and two trial types, thus behavioral outcomes can be measured as a proportion of correct trials while EEG analysis can focus on the brain patterns in response to the different trial types. For the 2-Back, this task seems to measure working memory since items are required to be stored in memory, recalled when the trial demands it, and the subject must manipulate information by storing new shapes in mind and discarding older shapes that are no longer needed. For replication, a detailed description of the experimental design, which includes an explanation of the tasks (the trial types, the number of trials, their ratios, etc.), the neuroimaging system (the type of EEG, number of channels, montage system, etc.), the stressors used (baseline, exercise, sleep deprivation) and characteristics of the sample (demographics and military background) will allow other researchers to recreate the study. For ethics, each subject goes through the consent process that gives an overview of the study, the expectations, and a justification for why it is being conducted. They will be told that they can leave the study at any time and that there will be no penalties for it. Additionally, precautions will be taken to make sure that subjects are safe through the process. This includes introducing stressors that are challenging but reasonable, with low risk of injury. Additionally, these risks need to be disclosed to the participants, so they are aware and agree to the terms of the study. All data collected will be kept confidential and labeled with an ID number. Lastly, some type of compensation will be made for their contribution. 

This experimental design shows a well-controlled study with decent internal validity. This is due to utilizing two well-known and respective cognitive tasks and by introducing stressors that have been used in other studies with success. Exercise is a commonly used measure for stress. It is present in both animal and human research, especially for studies related to the military since it is important. Heart rate is being capture for subjects while they exercise to confirm that they are putting enough effort. For sleep deprivation, a watch is given that measure the amount of sleep duration for the previous night of their last visit. Only subjects with less than 30 minutes of sleep (less than a full sleep cycle), will be allowed to participate. Thus, by having strict thresholds for what counts as stress (reaching a target hear rate or having less than 30 minutes of sleep), we can confidently state that any mean differences in performance for the tasks across the different testing days are related to stress. As mentioned, a potential draw back to internal validity is the lack of counterbalance, which may dimmish the effect sizes of our results assuming stress leads to poor performance and if there is a practice effect. 

Recruitment of members with a military background reduced the external validity of the findings to the general public. This is because there may be specific attributes of this population that differs from that of the general public. Examples could be level of fitness, baseline cognitive ability, and resistance to negative effects from sleep deprivation. However, the generalizability of these findings for military members is very high. The only concern that is how the construct of stress can generalize to common stressors in the military. Due to safety concerns, our stressors conditions are much more tempered than high intensity prolonged exercises experienced by military recruits or going days without sleep deprivation. Thus, our results on cognitive performance across testing days could be statistically significant but have a smaller effect size than would be expected from realistic military stressors.


We do not expect the limitations of internal or external validity to impact the interpretability of our results. There is similar research to more tamed versions of these stressors that have found significant differences in cognitive performance. The main issue that could occur is a potential lack of power in our models, which could result in type II errors. Twenty five subjects, while publishable, is not always ideal, especially if the effect size of stress on cognitive performance is small. 


### (5 pts) Planned Statistical Analyses/Mathematical Models

#### Model 1 (Behavioral) 

- Empty: $Y_{ij}= \beta_0+ u_{0j}+ e_{ij}$
- Restricted: $Y_{ij}= \beta_0+ \beta_{1} x_{1ij} + \beta_{2} x_{2ij} + u_{0j} + e_{ij}$
- Full: $Y_{ij}= \beta_0+ \beta_{1} x_{1ij} + \beta_{2} x_{2ij} + \beta_{3}(x_{1ij}*x_{2ij})  + u_{0j} + e_{ij}$

Where:

- $Y_{ij}$ = the proportion of correct trials for the target trial in the 2-back
- $\beta_{0}$ = the intercept
- $u_{0j}$ = random effects of the intercepts
- $\beta_1 x_{1ij}$ = the mean difference of sex (Males, Females) 
- $\beta_2 x_{2ij}$ = the mean difference of stress (Baseline, Exercise, Sleep Deprivation)
- $\beta_{3}(x_{1ij}*x_{2ij})$ = the interaction between stress and sex


#### Model 2: P300 (EEG)

- Empty: $Y_{ij}= \beta_0+ u_{0j}+ e_{ij}$
- Restricted: $Y_{ij}= \beta_0+ \beta_{1} x_{1ij} + \beta_{2} x_{2ij} + u_{0j} + e_{ij}$
- Full: $Y_{ij}= \beta_0+ \beta_{1} x_{1ij} + \beta_{2} x_{2ij} + \beta_3 x_{3ij} + u_{0j} + e_{ij}$

Where:

- $Y_{ij}$ = the proportion of correct trials for the target trial in the 2-back
- $\beta_{0}$ = the intercept
- $u_{0j}$ = random effects of the intercepts
- $\beta_1 x_{1ij}$ = the mean difference of sex (Males, Females) 
- $\beta_2 x_{2ij}$ = the mean differences in trial type (target, non-target)
- $\beta_3 x_{3ij}$ = the mean difference of stress (Baseline, Exercise, Sleep Deprivation)


### (15 pts) Results: 
- The type of statistical analysis computed
_ A general interpretation about the direction and size of effects
- Relevant statistical information about the effect (estimate, standard error, p values, confidence interval, effect sizes, etc.), any posthoc tests, contrasts, and simple slopes
- Model assumption checks 
- At least one table 
- At least one figure 


Due to the repeated measurement nature of the experiment, multilevel models were used to express the empty, restricted, and full models, with each subject having their own random intercept. For the behavioral analysis, restricted models included covariates and main effects while the full models included their interactions. For the EEG analysis, restricted models included only covariates while the full model included the main predictor stress conditions (labeled as day). Model comparison were used to indicate the model with the best fit, and main effects and interactions were interpreted using type III SS. Linear models were fitted using the lmer function in R with the lme4 package (v1.1.32, Bates et al., 2015). These hierarchical models accounted for unequal sample sizes across testing days. Mean accuracy on the working memory task (2-back) was analyzed with the fixed effects of stress (baseline, exercise, sleep deprivation), sex (M,F), and their interaction only on target trials. 

Post-hoc investigations of significant interactions terms were performed using pairwise comparisons with Tukey’s HSD adjustment for multiple comparison through the emmeans package in R (Lenth, 2023). To examine how stress conditions affect working memory processes, mean amplitudes of the P300 ERP amplitudes were calculated for the 2-back task. P300 amplitudes for each trial type (target vs non-target) were calculated as the maximum peak amplitude within a 300-500 ms time window post-stimulus onset, by averaging amplitudes 50 ms before and 50 ms after the peak. Linear mixed-effects models were used to predict 2-back P300 amplitudes from the factors stress (baseline, exercise, sleep deprivation), trial type (target, non-target), while controlling for sex (M, F). 
  
Since we were mostly interested in how stress conditions influence cognitive performance, contrasts were created to compare the means of baseline to exercise and baseline to sleep deprivation. Model comparisons showed that the full model had a significantly lower Akaike Information Criteria (AIC) than the restricted model, indicating a better fit. This model had a statistically significant main effect of stress (χ2(1) = 19.24, p < .001; $\eta_{p}^2$= .40), sex (χ2(1) = 7.74, p < .01;  $\eta_{p}^2$= .13), and interaction (χ2(1) = 9.97, p < .01;  $\eta_{p}^2$= .25) on the proportion of correct target trials (**Table 1**). The effect sizes from partial eta squares showed the largest contributor to the model was stress condition, which explained about 40% of the variance in the outcome, however, due to the significant interaction term, the emphasis will be on the moderation relationship. Follow up tests using pairwise comparisons on the interaction between stress and sex showed that for females, performance on target trials was significantly higher after exercise than at baseline (β = -0.21, *SE*= .048, p < .001) but was not significantly different for baseline versus sleep deprivation (β = -0.09, *SE*= .053,p = .25). For males, there were no significant difference between baseline and exercise (β = -0.04, *SE*=.041, p = .62) nor between baseline and sleep deprivation (β = 0.10, *SE*=.098, p = .08) on target performance (**Figure 1**).   
  
A linear mixed-effects model for P300 amplitudes of the 2-back showed a main effects of stress (χ2(2) = 10.24, p < .01; $\eta_{p}^2$= .16), trial type (χ2(1) = 16.27, p < .001; $\eta_{p}^2$= .25), and no main effect of sex (χ2(1) = 3.61, p = .06; $\eta_{p}^2$= .20). No interaction terms were included since model comparison showed no significant improvement to the overall model fit. Partial eta square also showed that the main effect of trial type was the largest contributor to explaining variance of brain activity. Follow-up tests on trial type using pairwise comparisons revealed that target trials produced larger P300 amplitudes than non-targets (β = -2.98, *SE*= .74,p < .01). Additionally, follow-up tests showed that P300 amplitudes for target and non-target trials were larger at baseline compared to after exercise (β = 3.07, *SE*= .97,p < .01) and were not significantly different between baseline and sleep deprivation (β = 2.12, *SE*= 1.09,p = .14).  


#### Figure 1:

```{r visualizing behavior performance}
text_parameters <-  theme(plot.title = element_text(size = 18,
                                  hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold"),
        axis.text = element_text(size = 12),
        plot.caption = element_text(size = 14,
                                    hjust = 0))

# Create a plot that looks for and sex differences 
VR.long %>%
  mutate(Day = ifelse(Day == "Day1", "Baseline",
                      ifelse(Day == "Day2", "Exercise", "Sleep\nDeprivation"))) %>%
  filter(Trial.Type == "Target") %>%
  ggplot(aes(x = Day, y = Performance)) +
  geom_boxplot(alpha = 0) +
  theme_classic() +
  facet_wrap(~Sex) +
  labs(title = "Proportion of Correct Target Trials\nAcross Stress Conditions",
       x = NULL,
       y = "Proportion of\nCorrect Target Trials") +
  text_parameters
```

#### Table 1

```{r creating an APA Table for the Nback LMEM Analysis}

# Save Omnibus Test
OmnibusTest <- data.frame(Anova(Model3, type = "III")) %>%
  round(3)

# Start Create our APA Table
Table1 <- tibble(Group = c("Subject", "Residual"),
                     Variance = round(c(0.19762^2, 0.12605^2),3),
                     `Std. dev.` = round(c(0.19762, 0.12605),3))

# Print the table that contains the random effects
Table1 %>%
  kbl(caption = "Random Effects") %>%
  kable_classic_2(full_width = F,  html_font = "Cambria", position = "left")

# Turn it into a tibble and add a Variable variable
row.names(OmnibusTest) <- NULL

OmnibusTest$Name <- c("Intercept", "Sex", "Stress", "Stress x Sex")

OmnibusTest2 <- OmnibusTest %>%
  select(Name, Chisq, Df, Pr..Chisq.)

# Print a table that contains the omnibus test
names(OmnibusTest2) <- c("Name","χ²", "Df", "p-value")

OmnibusTest2 %>%
  kbl(caption = "Fixed Effects") %>%
  kable_classic_2(full_width = F, html_font = "Cambria", position = "left")

```



### Interpretation
- of results as related to the problem statement and research questions (hint: it can be helpful to read your problem statement, research questions, and interpretation of results side by side as you do this). As part of this interpretation, include the following subsections:
- (10 pts) Conclusion. In 3-6 sentences, summarize your study and your interpretation of the primary findings. 
- (10 pts) Limitations. In 3-6 sentences, if you could do this study again, what would you change? What are the limitations of the study design, and how would you reasonably address them in future research?
- (10 pts) Implications. In 3-6 sentences, what are the practical/applied implications of the study as they relate to your research area? 
- (10 pts) At the end of the document (or as a separate document), include an appendix of all of your annotated R code and output. Please do NOT print this, but do ensure to upload it with your final submission.


In the 2-back task, only target trials were analyzed since they reflect working memory capability. Accuracy differences in target trials across stress conditions were moderated by sex, with females demonstrating better performance after exercise compared to baseline and no notable difference between baseline and sleep deprivation. Interestingly, males showed consistent performance across all stress conditions. These findings suggest that sleep deprivation may not significantly impact working memory in either sex and that exercise may uniquely enhance working memory in females. 

The analysis of the P300 ERP provided further insight into the neural underpinnings of working memory under different stress conditions. The analysis showed that the central-parietal P300 amplitude was larger for the less frequently presented stimuli (target) than for standard stimuli (non-target). This pattern was consistent across testing days and was further supported by the non-significant interaction between trial type and stress condition, suggesting that the brain could still effectively differentiate between standard and deviant stimuli in each task.  

Furthermore, P300 amplitudes were larger after exercise compared to baseline but showed no difference between baseline and sleep deprivation. These ERP findings slightly mirrored accuracy results, with larger amplitudes in stress conditions that led to performance improvement (post-exercise in the 2-back). Overall, these results do align with out conceptual framework by showing that conditions of stress do influence performance and mental processes. Based on power analysis not mentioned and overall effect sizes, it seems that the interpretation of the results are accurate and align with what was initially proposed. 

#### Limitations
The duration of each testing day (4+ hours) and the requirement to complete all visits within a month led to some attrition, resulting in unequal sample sizes across the stress conditions. Fortunately, mixed-effects models can estimate parameters and adjust them based on the availability of observations by weighting those with full data more heavily than those with missing data. Additionally, the P300 ERP analysis requires a sufficient number of clean correct trials to create reliable averages of the components. This approach reduces random noise in the data and captures the intended cognitive processes. However, it also introduces a bias against poor performers, particularly in the stress conditions, since they may not meet the required number of correct trials. 

#### Conclusion

In conclusion, this study highlights the nuanced effects of stress conditions, such as sleep deprivation and exercise, on working memory performance and its neural correlates. Behavioral data revealed sex differences, with females benefiting from exercise but remaining unaffected by sleep deprivation, while males showed consistent performance regardless of the stress condition. Neural findings, as indicated by P300 ERP amplitudes, complemented these behavioral patterns, demonstrating robust differentiation between target and non-target stimuli across all conditions. The larger P300 amplitudes following exercise align with the observed improvements in performance, particularly for females, reinforcing the potential cognitive benefits of physical activity. These results support the conceptual framework by illustrating how stress conditions can differentially influence cognitive performance and underlying neural processes.


## Analysis Code


#### Loading in the data

     
```{r loading in all reqwerquired data}
# Set working directory to where your GitHub repository is
GitHub = "C:/Users/lledesma.TIMES/Documents/GitHub/ONR_MBAP/"

# Set working directory to where the final data is
setwd(paste0(GitHub,"TimesServer/FINAL_DS/"))

# Load in VR behavioral data
All_VR <- read.csv("VR/NbackAccuracyWide.csv")

# Load in the VR RT 
All_RT <- read.csv("VR/NbackReactionTimeWide.csv")

# Load in demographics
demo <- read_excel("Demographics/ComprehensiveDescriptives.xlsx")

# Clean demo to include subjects we care for
demo <- demo %>%
  filter(Pilot == "Yes" & 
         Sex != "Intersex/Other")

# Introduce demographics into the GnG VR
All_VR <- All_VR %>%
  right_join(demo, by = "ID") %>%
  filter(!(Day %in% c("Day0", "DatenotsavedintheVisitorLog")))

# Introduce demographics into the GnG RT 
All_RT <- All_RT %>%
  right_join(demo, by = "ID") %>%
  filter(!(Day %in% c("Day0", "DatenotsavedintheVisitorLog")))


# Combine to only keep the Arrows and Reverse Arrows with No Distractor Condition (Wide format)
VR <- All_VR %>%
  filter(BlockName %in% c("2-Back AR w ND", "2-Back RAR w ND")) %>%
  group_by(ID, Day) %>%
  summarise(Sex,
            Age,
            trial.num_Non.Target = sum(trial.num_Non.Target),
            trial.num_Target = sum(trial.num_Target),
            trial.mean.correct_Non.Target = mean(trial.mean.correct_Non.Target),
            trial.mean.correct_Target = mean(trial.mean.correct_Target)) %>%
  unique() %>%
  ungroup() %>%
  mutate(ID_Day = paste0(ID,"_",Day))

# Combine to only keep the Color and Shape Fixed IS and Color and Shape Conditions for RT (wide format)
RT <- All_RT %>%
  filter(BlockName %in% c("2-Back AR w ND", "2-Back RAR w ND")) %>%
  group_by(ID, Day) %>%
  summarise(Sex,
            Age,
            Correct_Target_ms  = mean(Correct_Target_ms)) %>%
  unique() %>%
  ungroup() %>%
  mutate(ID_Day = paste0(ID,"_",Day))


# Load in EEG data
load("EEG ERPs/AR_RAR_FinalERPData.RData")
```



#### Behavioral Analysis


```{r Arrows wiqwqth No Distractors VR Analysis}
# Let's transform the data to long
VR.long <- VR %>%
  select(ID, Day, Sex, trial.mean.correct_Target, trial.mean.correct_Non.Target ) %>%
  pivot_longer(cols = c(trial.mean.correct_Non.Target , trial.mean.correct_Target),
               names_to = "Trial.Type",
               values_to = "Performance") %>%
  mutate(Trial.Type = ifelse(Trial.Type == "trial.mean.correct_Target", "Target", "NoTarget"),
         Trial.Type = factor(Trial.Type))

# Sperate the data by trial type
VRTarget <- filter(VR.long, Trial.Type == "Target")

# Create the unconditional model
AnDVR_unmodel <- lmer(Performance ~ (1|ID), data = VRTarget)
# summary(csVR_unmodel) 

# Paste the ICC
paste0("The adjusted ICC is: ", round(as.data.frame(performance::icc(AnDVR_unmodel)),3)[1])

# Convert variables into factors
VRTarget$Day <- as.factor(VRTarget$Day)
VRTarget$Sex <- as.factor(VRTarget$Sex)

# Check to make sure the dummy coding for day is correct
contrasts(VRTarget$Day)
contrasts(VRTarget$Sex)

# Create the model with the main predictor
Model1 <- lmer(Performance ~  Day + (1|ID), data = VRTarget)

# Create the model with Sex and the main predictor
Model2 <- lmer(Performance ~ Sex  + Day + (1|ID), data = VRTarget)

# Create the model with an interaction between Day and Sex
Model3 <- lmer(Performance ~ Sex  * Day + (1|ID), data = VRTarget)

# Model comparison
anova(Model1, Model2, Model3)

# Report the best model
Anova(Model3, type = "III")

# Use emmeans to look at the main effect of day
day_estimates <- emmeans(Model3, ~ Day)
pairs(day_estimates, adjust = "tukey")

# Use emmeans to look at the main effect of sex
sex_estimates <- emmeans(Model3, ~ Sex)
pairs(sex_estimates, adjust = "tukey")

# use emmeans to investigate the interaction
mean_estimates <- emmeans(Model3,  ~ Day | Sex)
mean_esti_df <- pairs(mean_estimates, adjust = "tukey")
data.frame(mean_esti_df)

# effect sizes
eta_squared(Model3, partial = TRUE)
```


#### Model Assumptions

```{r plotting tqwehe residualss, out.width= "49%"}
vif(Model2)
plot(resid(Model3))
hist(resid(Model3))

# Create the Q-Q plot
qqnorm(resid(Model3), main = "Q-Q Plot of Residuals")
qqline(resid(Model3), col = "black", lwd = 2)

```


#### EEG Model

- Subjects are the random effects and each subject only has three data points or less
- Errors look to be normally distributed (2nd and 3rd plot)
- Errors look to be evenly spread out in the first graph (no hetereskedasticity)
- Used the model without the interaction to get a better report of VIF values, they look good (less than 5). 



```{r removing bad plots , out.width = "50%", include= F, echo = F}
# Remove Outliers from the dataset
AR_RAR_FinalERPData <- AR_RAR_FinalERPData %>%
  filter(!(ID %in% outlierIDs))

# Save the bad plot in another object
badPlots <- c("121_Day3_NbackARND_RARND.set") #

badPlotsAR_RAR_FinalERPData <- AR_RAR_FinalERPData %>%
  filter(File_Name %in% badPlots)

# Remove the bad plots from the dataset
AR_RAR_FinalERPData <- AR_RAR_FinalERPData %>%
  filter(!(File_Name %in% badPlots))

# Let's transform the data to long
P300.long <- AR_RAR_FinalERPData %>%
  select(ID, Day, Sex, P300_NonTarget, P300_Target, P300_Difference) %>%
  pivot_longer(cols = c(P300_NonTarget, P300_Target, P300_Difference),
               names_to = "ERP_Type",
               values_to = "Power") %>%
  mutate(ERP_Type = factor(ERP_Type, levels = c("P300_NonTarget","P300_Target", "P300_Difference")))
```

```{r Arrow no Distracqewtor P300 Analysis a}
# Remove the P300 Different rows
P300a.long <- P300.long %>%
  filter(ERP_Type != "P300_Difference")

# Convert ERP_Type back to character then back to Factor
P300a.long$ERP_Type <- as.character(P300a.long$ERP_Type)
P300a.long$ERP_Type <- as.factor(P300a.long$ERP_Type)

# Create the unconditional model
csP3_unmodel <- lmer(Power ~ (1|ID), data = P300a.long)
#summary(csP3_unmodel) 

# Paste the ICC
paste0("The adjusted ICC is: ", round(as.data.frame(performance::icc(csP3_unmodel)),3)[1])
paste0("The unadjusted ICC is: ", round(as.data.frame(performance::icc(csP3_unmodel)),3)[2])

# Convert variables into factors
P300a.long$Day <- as.factor(P300a.long$Day)
P300a.long$Sex <- as.factor(P300a.long$Sex)
P300a.long$ERP_Type <- as.factor(P300a.long$ERP_Type)

# Check the contrasts
contrasts(P300a.long$Day)
contrasts(P300a.long$Sex)
contrasts(P300a.long$ERP_Type) <- c(1, 0)

# Create a model with just the main effect of Sex
P300_model1 <- lmer(Power ~  Sex + (1|ID), data = P300a.long)

# Create a model with the main effect of Day and Trial Type
P300_model2 <- lmer(Power ~  Sex + ERP_Type + (1|ID), data = P300a.long)

# Create a model with the main effects of Day, Trial Type and Sex
P300_model3 <- lmer(Power ~  Sex + ERP_Type + Day + (1|ID), data = P300a.long)


# Model comparison
anova(P300_model1, P300_model2, P300_model3)

# Write out the omnibus test using type 3 SS
Anova(P300_model3, type = "III")

# Engage in follow up tests for trial type
ERP_post_df <- data.frame(pairs(emmeans(P300_model3, ~ERP_Type, adjust = "tukey")))
ERP_post_df

# Engage in follow up tests for Day
Stress_post_df <- data.frame(pairs(emmeans(P300_model3, ~Day, adjust = "tukey")))
Stress_post_df

# effect sizes
eta_squared(P300_model3, partial = TRUE)
```

### Model 2: Assumptions

- Subjects are the random effects and each subject only has three data points or less
- Errors look to be normally distributed (2nd and 3rd plot)
- Errors look to be evenly spread out in the first graph (no hetereskedasticity)
- Vif values are okay.

```{r plotting theqwe residuals, out.width= "49%"}
vif(P300_model2)
plot(resid(P300_model2))
hist(resid(P300_model2))

# Create the Q-Q plot
qqnorm(resid(P300_model2), main = "Q-Q Plot of Residuals")
qqline(resid(P300_model2), col = "black", lwd = 2)

```

