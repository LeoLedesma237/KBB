ERPValues_df$File_Name <- paste0(substr(ERPValues_df$ERPValueFileName, 1, 15),".set")
ERPValues_df$TrialType <- ifelse(grepl("_Go_", ERPValues_df$ERPValueFileName), "Go", "NoGo")
# Keep the file names that are eligible
EligibleERPValues_df <- ERPValues_df %>%
filter(File_Name %in% EligibleCS$File_Name)
# Quality control: nrow(EligibleERPValues_df) == nrow(EligibleCS)*2
# Create a for loop to reads in the Go and NoGo files that are eligible(We only care about Cz)
# Then does some cleaning
# And calculates the P300 and saves them in one list
# And changes them so they can be graphed and saves them in another list
CZP300_list <- list()
CZGraph_list <- list()
for(ii in 1:nrow(EligibleERPValues_df)) {
# Save current ERPvalue dataset
CurrentData <- read.csv(paste0(ERPValues_PathWay, ERPValues_df$ERPValueFileName[ii]), sep = "\t")
# Filter to keep only Cz channel information
CzData <- filter(CurrentData, time == "CZ")
# Drop the time  variable since all of this is Cz
CzData <- select(CzData, - time)
# Let's calculate the P300 here (window average)
P300Window <- select(CzData, X300.0000:X600.0000)
P300 <- rowMeans(P300Window)
# Let's clean the CzData vector so we can plot this later
# Convert it to long
CzData_long <- stack(CzData)
# Change the variable names
names(CzData_long) <- c("Power", "Time_ms")
# Convert the Time variable to numeric
CzData_long$Time_ms <- as.numeric(gsub("\\D", "", CzData_long$Time_ms))/ 10000
# Make all values left of 0 into negative digits
zeroPosition <- which(CzData_long$Time_ms == 0)
multiplier <- c(rep(-1, zeroPosition), rep(1, length(CzData_long$Time_ms) - zeroPosition))
CzData_long$Time_ms <- CzData_long$Time_ms * multiplier
#Save the lists with a) P300 value and b) cleaned Power and Time for Graphs
CZP300_list[[ii]] <- P300
CZGraph_list[[ii]] <- CzData_long
}
# Convert the P300 list into a variable and add it the data frame
EligibleERPValues_df$P300 <- do.call(c, CZP300_list)
# Save the Graphing information nested with the cells of the data frame (this is temporary)
EligibleERPValues_df$GraphInfo <- CZGraph_list
# Convert this data frame to wide format so we can joing it with the Eligible one
EligibleERPValues_wide <- EligibleERPValues_df %>%
select(- ERPValueFileName) %>%
pivot_wider(names_from = TrialType, values_from = c(P300, GraphInfo))
# Now take this dataset and join it to the original one
FinalERPData <- EligibleERPValues_wide %>%
left_join(EligibleCS, by = c("File_Name", "ID"))
setwd("C:/Users/lledesma.TIMES/Documents")
save(FinalERPData, file = "my_data.RData")
paste0(TimesServer, "Data/FINAL_DS/EEG ERPs/CS_FinalERPData.RData"))
paste0(TimesServer, "Data/FINAL_DS/EEG ERPs/CS_FinalERPData.RData")
paste0(TimesServer, "Data/FINAL_DS/EEG ERPs/CS_FinalERPData.RData")
# Save the dataset to an .RData file
save(CS_FinalERPData, file = paste0(TimesServer, "Data/FINAL_DS/EEG ERPs/CS_FinalERPData.RData"))
# Now take this dataset and join it to the original one
CS_FinalERPData <- EligibleERPValues_wide %>%
left_join(EligibleCS, by = c("File_Name", "ID"))
# Save the dataset to an .RData file
save(CS_FinalERPData, file = paste0(TimesServer, "Data/FINAL_DS/EEG ERPs/CS_FinalERPData.RData"))
load("M:/Data/FINAL_DS/EEG ERPs/CS_FinalERPData.RData")
# Practice loading in the data
load(paste0(TimesServer, "Data/FINAL_DS/EEG ERPs/CS_FinalERPData.RData"))
# Have this pathway ready
TimesServer = "//files.times.uh.edu/labs/grigorenko_ONR-MPAB/"
load(paste0(TimesServer, "Data/FINAL_DS/EEG ERPs/CS_FinalERPData.RData"))
View(CS_FinalERPData)
# This R Script will be preparing the values of the ERPs for the eligible EEG recordins for the
# Color and Shape condition.
# Load in the eligible EEG file names
EligibleCSFI <- read_excel(paste0(TimesServer, "Data/FINAL_DS/EEG ERPs/CSFI_EligibleEEGFiles.xlsx"))
# Read in the ERPs of each of these files
ERPValues_PathWay = paste0(TimesServer, 'Data/Preprocessed/EEG/CreatingERPs/PILOT/ERPValues/Color_and_Shape_fixed_ISI/')
# Create a dataframe to take ERPValue file names and separate them into different variables
ERPValues_df <- data.frame(ERPValueFileName = dir(ERPValues_PathWay))
ERPValues_df$ID <- as.numeric(substr(ERPValues_df$ERPValueFileName, 1, 3))
ERPValues_df$Day <- substr(ERPValues_df$ERPValueFileName, 5, 8)
ERPValues_df$File_Name <- paste0(substr(ERPValues_df$ERPValueFileName, 1, 15),".set")
ERPValues_df$TrialType <- ifelse(grepl("_Go_", ERPValues_df$ERPValueFileName), "Go", "NoGo")
# Keep the file names that are eligible
EligibleERPValues_df <- ERPValues_df %>%
filter(File_Name %in% EligibleCSFI$File_Name)
CZP300_list <- list()
CZGraph_list <- list()
EligibleERPValues_df
ERPValues_PathWay
ERPValues_PathWay = paste0(TimesServer, 'Data/Preprocessed/EEG/CreatingERPs/PILOT/ERPValues/Color_and_Shape_fixed_ISI/')
dir(ERPValues_PathWay)
# Create a dataframe to take ERPValue file names and separate them into different variables
ERPValues_df <- data.frame(ERPValueFileName = dir(ERPValues_PathWay))
ERPValues_df
ERPValues_df$ID <- as.numeric(substr(ERPValues_df$ERPValueFileName, 1, 3))
ERPValues_df$Day <- substr(ERPValues_df$ERPValueFileName, 5, 8)
ERPValues_df$File_Name <- paste0(substr(ERPValues_df$ERPValueFileName, 1, 15),".set")
ERPValues_df$TrialType <- ifelse(grepl("_Go_", ERPValues_df$ERPValueFileName), "Go", "NoGo")
ERPValues_df
# Keep the file names that are eligible
EligibleERPValues_df <- ERPValues_df %>%
filter(File_Name %in% EligibleCSFI$File_Name)
EligibleERPValues_df
ERPValues_df
head(ERPValues_df) %>% view()
dir(ERPValues_PathWay)
# Create a dataframe to take ERPValue file names and separate them into different variables
ERPValues_df <- data.frame(ERPValueFileName = dir(ERPValues_PathWay))
ERPValues_df$ID <- as.numeric(substr(ERPValues_df$ERPValueFileName, 1, 3))
ERPValues_df$Day <- substr(ERPValues_df$ERPValueFileName, 5, 8)
ERPValues_df$File_Name <- paste0(substr(ERPValues_df$ERPValueFileName, 1, 17),".set")
ERPValues_df$TrialType <- ifelse(grepl("_Go_", ERPValues_df$ERPValueFileName), "Go", "NoGo")
# Keep the file names that are eligible
EligibleERPValues_df <- ERPValues_df %>%
filter(File_Name %in% EligibleCSFI$File_Name)
EligibleERPValues_df
CZP300_list <- list()
CZGraph_list <- list()
1:nrow(EligibleERPValues_df)
for(ii in 1:nrow(EligibleERPValues_df)) {
# Save current ERPvalue dataset
CurrentData <- read.csv(paste0(ERPValues_PathWay, ERPValues_df$ERPValueFileName[ii]), sep = "\t")
# Filter to keep only Cz channel information
CzData <- filter(CurrentData, time == "CZ")
# Drop the time  variable since all of this is Cz
CzData <- select(CzData, - time)
# Let's calculate the P300 here (window average)
P300Window <- select(CzData, X300.0000:X600.0000)
P300 <- rowMeans(P300Window)
# Let's clean the CzData vector so we can plot this later
# Convert it to long
CzData_long <- stack(CzData)
# Change the variable names
names(CzData_long) <- c("Power", "Time_ms")
# Convert the Time variable to numeric
CzData_long$Time_ms <- as.numeric(gsub("\\D", "", CzData_long$Time_ms))/ 10000
# Make all values left of 0 into negative digits
zeroPosition <- which(CzData_long$Time_ms == 0)
multiplier <- c(rep(-1, zeroPosition), rep(1, length(CzData_long$Time_ms) - zeroPosition))
CzData_long$Time_ms <- CzData_long$Time_ms * multiplier
#Save the lists with a) P300 value and b) cleaned Power and Time for Graphs
CZP300_list[[ii]] <- P300
CZGraph_list[[ii]] <- CzData_long
}
# Convert the P300 list into a variable and add it the data frame
EligibleERPValues_df$P300 <- do.call(c, CZP300_list)
# Save the Graphing information nested with the cells of the data frame (this is temporary)
EligibleERPValues_df$GraphInfo <- CZGraph_list
# Convert this data frame to wide format so we can joing it with the Eligible one
EligibleERPValues_wide <- EligibleERPValues_df %>%
select(- ERPValueFileName) %>%
pivot_wider(names_from = TrialType, values_from = c(P300, GraphInfo))
# Now take this dataset and join it to the original one
CSFI_FinalERPData <- EligibleERPValues_wide %>%
left_join(EligibleCSFI, by = c("File_Name", "ID"))
# Save the dataset to an .RData file
save(CSFI_FinalERPData, file = paste0(TimesServer, "Data/FINAL_DS/EEG ERPs/CSFI_FinalERPData.RData"))
load("M:/Data/FINAL_DS/EEG ERPs/CS_FinalERPData.RData")
load("M:/Data/FINAL_DS/EEG ERPs/CSFI_FinalERPData.RData")
View(CS_FinalERPData)
View(CSFI_FinalERPData)
View(CS_FinalERPData)
# This is the master script for the ONR Behavioral Data
# Manually set your working directory to ONR_MBAP Folder
# Use the blue gear to do this
# Set the following working directories (must end in /)
# These will be changed later (except for last one) to the SymbolicLinks
SharePoint1 = "C:/Users/lledesma.TIMES/University Of Houston/UH-ONR - Documents/"
SharePoint2 = "C:/Users/lledesma.TIMES/University Of Houston/UH ONR Scheduling - General/"
TimesServer = "//files.times.uh.edu/labs/grigorenko_ONR-MPAB/"
R_Pathways = "Scoring/"
##################################################################################
########################## The Rest is Automatic #################################
##################################################################################
# Load the package
library(tidyverse)
library(qualtRics)
library(readxl)
library(readr)
library(openxlsx)
# Load in the SharePoint IDs, Qualified Screener, SONA Screener, and Visitor Log
General_IDs <- read_csv(paste0(SharePoint1,"PilotIDs.csv")) %>% suppressMessages()
Visitor_Log <- read_excel(paste0(SharePoint1, "/ONRTestingVisitLog.xlsx")) %>% suppressMessages()
Qualified_Screener <- read_excel(paste0(SharePoint2, "/Study Screening.xlsx"),sheet = "Qualified") %>% suppressMessages()
SONA_Screener <- read_excel(paste0(SharePoint2, "/Study Screening.xlsx"),sheet = "SONA Qualified") %>% suppressMessages()
# Write the saving pathways on the server (for screeners)
save.pathway.IDs <- paste0(TimesServer,"Data/Raw_Data/Screeners/PilotIDs.csv")
save.pathway.QS <- paste0(TimesServer,"Data/Raw_Data/Screeners/Qualified_Screener.xlsx")
save.pathway.SS <- paste0(TimesServer,"Data/Raw_Data/Screeners/SONA_Screener.xlsx")
save.pathway.VS <- paste0(TimesServer,"Data/Raw_Data/Screeners/VisitLog.xlsx")
# Save these data
write_csv(x= General_IDs, file = save.pathway.IDs)
write.xlsx(x= Qualified_Screener, file = save.pathway.QS)
write.xlsx(x= SONA_Screener, file = save.pathway.SS)
write.xlsx(x= Visitor_Log, file = save.pathway.VS)
# Set up the URL to download the data from
Datacenter.ID <- "gov1"
URL <- paste(Datacenter.ID, ".qualtrics.com/", sep ="")
# Write in the API Token to give us permission to download the data
API.Token <- "yTVOklVpIbt4iEc78XqFeSNAbLzzWKbR0IiAzcMj"
# Write the data IDs so Qualtrics knows what we want downloaded
CFIT.code <- "SV_1X05QiOaRvgk5T0"
ONRQuestionnaires.code <- "SV_6S75F0IfDySTrW6"
# Enter API info
qualtrics_api_credentials(api_key = API.Token,
base_url = URL) # Datacenter ID + ".qualtrics.com/"
# (Optional) Prints out the ids of all surveys on Qualtrics
surveys <- all_surveys()
#Set Time Zone
Sys.setenv(TZ = "UTC")
#Download the Qualtrics Data
CFIT <- suppressMessages(fetch_survey(surveyID = CFIT.code, convert = FALSE, label = FALSE)) # convert and label FALSE downloads the data as numeric, delete for choice
ONRQuestionnaires <- suppressMessages(fetch_survey(surveyID = ONRQuestionnaires.code, convert = FALSE, label = TRUE)) # Keep it like this to import AO!
# Save these data in their Raw Format
save.pathway.CFIT <- paste0(TimesServer,"Data/Raw_Data/Qualtrics/CFIT_Raw.xlsx")
save.pathway.ONRQ <- paste0(TimesServer,"Data/Raw_Data/Qualtrics/ONRQuestionnaires_Raw.xlsx")
# Save each data in its raw form
write.xlsx(x= CFIT, file = save.pathway.CFIT)
write.xlsx(x= ONRQuestionnaires, file = save.pathway.ONRQ)
# Remove most of global environment objects  to declutter
rm(list = ls()[!(ls() %in% c("TimesServer", "R_Pathways"))])
## Creating a Quality Control Report from the Scripts Below
ScriptName = c()
ReportLog = c()
# Wait 2 seconds
Sys.sleep(2)
# This is the script for organizing demographic information
# Load in Packages
library(tidyverse)
library(readxl)
library(lubridate)
library(openxlsx)
# Load in the data for the Qualified Screener
headers <-  read_excel(paste0(TimesServer, "Data/Raw_Data/Screeners/Qualified_Screener.xlsx"),
col_names = T) %>% suppressMessages()
Qualified_Screener <- read_excel(paste0(TimesServer,"Data/Raw_Data/Screeners/Qualified_Screener.xlsx"),
skip = 1, col_names = T) %>% suppressMessages()
# Rename using the names from headers
names(Qualified_Screener) <- names(headers)
# Obtain name, Email and Sex
Qualified_Screener <- Qualified_Screener %>%
select(first.name = Q95,
last.name = Q96,
Email = Q94,
Sex,
Race = RE1,
Ethnicity = RE2,
Caregiver.Country = Q104)
# Mutate the email so all emails are lower case
Qualified_Screener$Email <- tolower(Qualified_Screener$Email)
# Just in case, make sure there are no spaces in the emails
Qualified_Screener$Email <- gsub("\\s+", "", Qualified_Screener$Email)
# Create an Indian vs nonIndian group
Qualified_Screener$Indian.Status <- ifelse(Qualified_Screener$Caregiver.Country == "India", "Indian", "not-Indian")
# Load in the SONA Qualified data
headers2 <- read_excel(paste0(TimesServer,"Data/Raw_Data/Screeners/SONA_Screener.xlsx"),
col_names = T) %>% suppressMessages()
Sona_Screener <- read_excel(paste0(TimesServer,"Data/Raw_Data/Screeners/SONA_Screener.xlsx"),
skip = 1, col_names = T) %>% suppressMessages()
# Rename using the names from headers2
names(Sona_Screener) <- names(headers2)
# Obtain name, Email and Sex
Sona_Screener <- Sona_Screener %>%
select(first.name = Q95,
last.name = Q96,
Email = Q94,
Sex,
Race = RE1,
Ethnicity = RE2,
Caregiver.Country = Q104)
# Mutate the email so all emails are lower case
Sona_Screener$Email <- tolower(Sona_Screener$Email)
# Just in case, make sure there are no spaces in the emails
Sona_Screener$Email <- gsub("\\s+", "", Sona_Screener$Email)
# Create an Indian vs nonIndian group
Sona_Screener$Indian.Status <- ifelse(Sona_Screener$Caregiver.Country == "India", "Indian", "not-Indian")
# Save Sona Screeners whose emails are not present in Qualified
SONA_Emails_Not_In_Qualified_Screener <- Sona_Screener %>%
filter(!(Email %in% Qualified_Screener$Email))
# Bind these Screener information together
Final.Screener <- rbind(Qualified_Screener,
SONA_Emails_Not_In_Qualified_Screener)
# Load the data
General_IDs <- tibble(read_csv(paste0(TimesServer,"Data/Raw_Data/Screeners/PilotIDs.csv"))) %>% suppressMessages()
# Select variables of interest
General_IDs <- General_IDs %>%
select(ID = ParticipantID,
Participant.Name = `Participant Name`,
Email,
DOB = Birthdate,
Withdrew = Status) %>%
arrange(ID) %>%
mutate(ID = as.numeric(ID))
# Convert the Status variable into a withdrawn variable
General_IDs$Withdrew <- ifelse(General_IDs$Withdrew  %in% c("Withdrew", "Timed out/lost contact"),
General_IDs$Withdrew,
"-")
# Mutate the email string so they are all lower case
General_IDs$Email <- tolower(General_IDs$Email)
# Just in case, make sure there are no spaces in the emails
General_IDs$Email <- gsub("\\s+", "", General_IDs$Email)
# Change DOB into a date variable
General_IDs$DOB <- mdy(General_IDs$DOB)
# Join this to the Qualified Screener
General_IDs.joined <- General_IDs %>%
left_join(Final.Screener, by = "Email")
# Drop any NA's for ID
General_IDs.joined <- drop_na(General_IDs.joined,ID)
# Load in the Visitor Log
Vis.Log <- read_excel(paste0(TimesServer,"Data/Raw_Data/Screeners/VisitLog.xlsx")) %>% suppressMessages()
# Calculate completion status
Vis.Log.Days <- select(Vis.Log, ID, `Day 0 Date`, `Day 1 Date`, `Day 2 Date`, `Day 3 Date` )
# Drop rows that are missing data for ID
Vis.Log.Days <- drop_na(Vis.Log.Days, ID)
# Count the number of columns per row that are NOT missing
Vis.Log.Days$Completed.Days <- rowSums(!is.na(Vis.Log.Days)) - 1
Vis.Log.Days <- mutate(Vis.Log.Days, Complete = ifelse(Completed.Days == 4,
"Completed",
"Partial"))
Vis.Log.Days2 <- select(Vis.Log.Days, ID, Completed.Days, Complete)
# Join this information back into Vis.Log
Vis.Log <- Vis.Log %>%
left_join(Vis.Log.Days2, by = "ID")
# Select the variables of interest
Vis.Log <- Vis.Log %>%
select(ID, Day0 = `Day 0 Date`, Completed.Days, Complete)
# Some data cleaning
Vis.Log$ID <- as.numeric(Vis.Log$ID)
Vis.Log$Day0 <- substr(x = Vis.Log$Day0, start = 1, stop = 10)
Vis.Log$Day0 <- ymd(Vis.Log$Day0)
# Drop any NA's from ID
Vis.Log <- drop_na(Vis.Log, ID)
# Join the datasets
General_IDs.Vis.Log.joined <- General_IDs.joined %>%
left_join(Vis.Log, by = "ID")
# Calculate Age
General_IDs.Vis.Log.joined <- General_IDs.Vis.Log.joined %>%
mutate(Age.Weeks = difftime(Day0, DOB, units = "weeks"),
Age = round(as.numeric(Age.Weeks)/52,1))
# Remove Identifiable Information
demographics <- General_IDs.Vis.Log.joined %>%
select(ID, DOB, Age, Sex, Race, Ethnicity, Completed.Days, Complete, Indian.Status, Withdrew)
# Create a save pathway for Notes
save.pathway <- paste0(TimesServer,"/Data/Demographics/ComprehensiveDescriptives.xlsx")
# Save the Notes as a CSV
write.xlsx(x = demographics, save.pathway)
##
## Quality Control
##
# first names matched correctly
General_IDs.Vis.Log.joined %>%
select(ID, Participant.Name, first.name, last.name)#%>%
#view()
# missing DOB or Sex
missingData <- demographics %>%
filter(!complete.cases(DOB,Sex))
# duplicate IDs
duplicateIDs <- demographics$ID[duplicated(General_IDs.joined$ID)]
duplicateIDs
# Create a log of potential problems
notes <- paste(missingData$ID, "is missing demo data")
script <- rep("Demographics_Scoring.R",length(notes))
ReportLog = c(ReportLog, notes)
ScriptName = c(ScriptName, script)
# This is the script for introducing Pilot status (ROTC/Military) into demographic information
# Load in Packages
library(tidyverse)
library(readxl)
library(openxlsx)
# Load in the Questions
Data <- read_excel(paste0(TimesServer,"Data/Raw_Data/Qualtrics/ONRQuestionnaires_Raw.xlsx")) %>% suppressMessages()
# Extract the descriptive names of the data
Data.Questions <- Data[1,] %>%
select(ID, `ROTC Exp1`:`ROTC Exp7`, ME1:ME9, FEE1:FEE5)
# Convert ID into numeric
Data$ID <- as.numeric(Data$ID)
# Drop NA's in the ID column
Data <- drop_na(Data, ID)
# Select variables of interest
Military.Exercise.data <- Data %>%
select(ID, `ROTC Exp1`:`ROTC Exp7`, ME1:ME9, FEE1:FEE5)
# Create a variable indicating military or ROTC experience
Military.Exercise.data <- Military.Exercise.data %>%
mutate(ROTC.Military.status = case_when(
`ROTC Exp1` == "Yes" ~ "Yes",
ME1 == "Yes" ~ "Yes",
TRUE ~ "No"
))
# Save our pilot sample
Pilot.sample <- Military.Exercise.data %>%
filter(ROTC.Military.status == "Yes")
# Quality check
sum(is.na(Pilot.sample$`ROTC Exp1`))
sum(is.na(Pilot.sample$ME1))
# Create the three groups
Pilot.sample <- Pilot.sample %>%
mutate(Group = case_when(
`ROTC Exp1` == "Yes" & ME1 == "No" ~ "ROTC Only",
`ROTC Exp1` == "No" & ME1 == "Yes" ~ "Military Only",
`ROTC Exp1` == "Yes" & ME1 == "Yes" ~ "ROTC & Military",
TRUE ~ "Error"
)
)
# Obtain all possible responses to staying in the program or former
unique(Pilot.sample$`ROTC Exp3`)
unique(Pilot.sample$ME3)
# Create a former vs current
Pilot.sample <- Pilot.sample %>%
mutate(Current = case_when(
`ROTC Exp3` == "Yes" | `ROTC Exp3` == "No, I commissioned out of the program" | ME3 == "Yes" ~ "Current",
`ROTC Exp3` == "No, I am no longer in the program" | ME3 == "No (I am Veteran)" ~ "Former",
TRUE ~ "Error"
)
)
# Transform the data to save it for the Comprehensive Descriptives
Pilot.sample2 <- select(Pilot.sample, ID, Pilot = ROTC.Military.status)
Pilot.sample2 <- mutate(Pilot.sample2, ID = as.numeric(ID))
# Load in demographic information
demographics <- read_excel(paste0(TimesServer,"Data/Demographics/ComprehensiveDescriptives.xlsx")) %>% suppressMessages()
# Join the datasets
Comprehensive.Descriptives <- demographics %>%
full_join(Pilot.sample2, by = "ID")
# Add values for non-pilot subjects
Comprehensive.Descriptives <- Comprehensive.Descriptives %>%
mutate(Pilot = ifelse(is.na(Pilot), "-", Pilot))
# Create a save pathway for Notes
save.pathway <- paste0(TimesServer,"/Data/Demographics/ComprehensiveDescriptives.xlsx")
# Save the Notes as a CSV
write.xlsx(x = Comprehensive.Descriptives, save.pathway)
# Completed Pilot
Comprehensive.Descriptives %>%
arrange(desc(Pilot), desc(Completed.Days))
view(Pilot.sample)
# Load in package
library(tidyverse)
library(robotoolbox)
library(openxlsx)
library(readxl)
# Set working directory to Root Folder
Root.Folder <- "C:/Users/lledesma.TIMES/Documents/KBB"
setwd(Root.Folder)
# API Token
token <- "947975196832610fca8a1673d54f0530c7cb8275"
# Setting up KoBo
kobo_setup(url = "https://kf.kobotoolbox.org",
token = token)
# Kobo Settings (Quality Control)
kobo_settings()
# Viewing the data
all.data.l <- kobo_asset_list()
# Write the uids for all needed data
df.uid <- data.frame(
ASEBA_YSR.iud = "a6qiRpZCN5Y79dPAXMtb4A",
Atlantis.iud = "aSp3rJjnNFGrEN9TvTJE9Z",
BRIEF2_SF.iud = "aTBTDSaspJjMyx8sWRDzbc",
PatternReas.iud = "aSCbRS4rUwDPLaAGvaHztc",
Triangles_LettrDig.iud = "aKBKpKnKssVquL3yxWqx8G",
ZAT.iud = "aSoQexoZ8NAeBqTAm9sqQt",
ASEBA_CBC.iud = "aKuaJqgcuCv5GAbmXdAbt6",
BRIEF2_Parent.iud = "a8crqFHGueNo9WDa6D8kPa",
HomeEnv.iud = "aMsdG3VCzxGbCutgMtkLjq",
PSC.iud = "a4t7cAdJvHnmagPQArZ9yX",
PSQ.iud = "aGdRnPPQeFAV64ha5fxxpP",
VinelandII.iud = "aHP8oarPVKEfGAA3L87QRH",
CFM2_4.iud = "aGvHGCmV9HF9yzsQqCjuJN",
CFM5_17.iud = "a3xZkViikGeNqbuZC7hAzb"
)
# Transpose and rename df.iud
df.uid.t <- data.frame(t(df.uid))
names(df.uid.t) <- "uid"
# Add Child  Parent Assessment Label
df.uid.t$label <- c(rep("Children", 6), rep("Adults", 6), rep("Screener",2))
# Add Partial Pathway
df.uid.t <- df.uid.t %>%
mutate(raw.pathway = case_when(
label == "Children" ~"2_behavioral_assessments/Children/Raw",
label == "Adults" ~ "2_behavioral_assessments/Adults/Raw",
label == "Screener" ~ "1_screener/Raw"
))
# Import all data into a list
all.data.list <- list()
for(ii in 1:nrow(df.uid.t)) {
# Import the data
all.data.list[[ii]] <- kobo_submissions(df.uid.t$uid[ii])
# Name the list elements
names(all.data.list)[ii] <- gsub(".iud" ,"", row.names(df.uid.t)[ii])
# Check progress
print(paste("Importing ",row.names(df.uid.t)[ii]," (",ii,"/",nrow(df.uid.t),")", sep=""))
}
# Saving the raw data in their respective raw_data folder
for(ii in 1:length(all.data.list)) {
# Create The Save Pathway
save.pathway = paste(Root.Folder,"/",
df.uid.t$raw.pathway[ii], "/",
names(all.data.list),"_Raw.xlsx", sep="")[ii]
# Select the data to save
data <- all.data.list[[ii]]
# Save each data in its raw form
write.xlsx(x= data, file = save.pathway)
# Check progress
print(paste("Saving ",row.names(df.uid.t)[ii]," (",ii,"/",nrow(df.uid.t),")", sep=""))
}
# Wait 2 seconds
Sys.sleep(2)
# Change the directory to the location of the scripts
setwd("~/GitHub/LeoWebsite/KBB.Scripts/Scoring")
# Score the data
source("PatternReasoning.Scoring.R")
source("TrianglesAndLetterDigitSpan.Scoring.R")
source("ReceptiveVocabulary.Scoring.R")
source("PediatricSymptomChecklist.Scoring.R")
source("PhysicalData.Scoring.R")
# Emerged Problems
source("ErrorManagement.Scoring.R")
print(All.notes)
